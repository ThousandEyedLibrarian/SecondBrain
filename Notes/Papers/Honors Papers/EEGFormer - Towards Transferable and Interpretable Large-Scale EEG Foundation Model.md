EEGFormer addresses a critical limitation in [[Electroencephalography (EEG)]] analysis where existing [[Self-Supervised Learning]] approaches only pre-train on individual datasets for single downstream tasks, failing to leverage the abundance of available unlabelled EEG data. The authors propose a novel foundation model that employs vector-quantised learning ([[wav2vec 2.0 - a framework for self-supervised learning of speech representations]]) with a [[Transformer]] architecture, diverging from conventional mask reconstruction strategies. 

The approach segments multi-channel EEG signals into patches after frequency domain conversion via [[Fast-fourier Transform (FFT)]], then uses a Transformer encoder followed by [[Vectors]] quantisation to generate discrete tokens representing EEG patterns. This discrete representation learning paradigm enables the model to create an interpretable [[Neural Codebook (NC)]] of EEG patterns while learning universal representations. The architecture consists of a Transformer encoder (6-12 layers depending on model size), a vector quantiser that maps patch representations to discrete codebook indices, and a shallow Transformer decoder for reconstruction.

The model demonstrates substantial empirical validation through pre-training on the massive 1.7TB TUH Corpus dataset and evaluation across five downstream tasks including seizure detection, abnormality detection, and artefact classification. EEGFormer achieves significant performance improvements, with 15.8% gains on neonatal [[Seizure]] detection and 14.1% on seizure detection tasks under the AUPRC metric compared to existing baselines. Critically, the model exhibits strong transferability across different EEG datasets and tasks, including successful transfer to the Neonate dataset which lies outside the TUH corpus. The discrete codebook representation provides interpretability advantages, enabling identification of clinically meaningful patterns such as spike-wave complexes associated with epileptiform discharges. This interpretability is particularly valuable in healthcare applications where model transparency is essential for clinical adoption and trust.

---

_This summary was generated by Claude Sonnet 4 and amended by me._